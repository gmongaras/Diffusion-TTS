{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.api import TTS\n",
    "import torch\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a multi-speaker and multi-lingual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No API token found for üê∏Coqui Studio voices - https://coqui.ai \n",
      "Visit üîóhttps://app.coqui.ai/account to get one.\n",
      "Set it as an environment variable `export COQUI_STUDIO_TOKEN=<token>`\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tts_models/multilingual/multi-dataset/your_tts',\n",
       " 'tts_models/multilingual/multi-dataset/bark',\n",
       " 'tts_models/bg/cv/vits',\n",
       " 'tts_models/cs/cv/vits',\n",
       " 'tts_models/da/cv/vits',\n",
       " 'tts_models/et/cv/vits',\n",
       " 'tts_models/ga/cv/vits',\n",
       " 'tts_models/en/ek1/tacotron2',\n",
       " 'tts_models/en/ljspeech/tacotron2-DDC',\n",
       " 'tts_models/en/ljspeech/tacotron2-DDC_ph',\n",
       " 'tts_models/en/ljspeech/glow-tts',\n",
       " 'tts_models/en/ljspeech/speedy-speech',\n",
       " 'tts_models/en/ljspeech/tacotron2-DCA',\n",
       " 'tts_models/en/ljspeech/vits',\n",
       " 'tts_models/en/ljspeech/vits--neon',\n",
       " 'tts_models/en/ljspeech/fast_pitch',\n",
       " 'tts_models/en/ljspeech/overflow',\n",
       " 'tts_models/en/ljspeech/neural_hmm',\n",
       " 'tts_models/en/vctk/vits',\n",
       " 'tts_models/en/vctk/fast_pitch',\n",
       " 'tts_models/en/sam/tacotron-DDC',\n",
       " 'tts_models/en/blizzard2013/capacitron-t2-c50',\n",
       " 'tts_models/en/blizzard2013/capacitron-t2-c150_v2',\n",
       " 'tts_models/en/multi-dataset/tortoise-v2',\n",
       " 'tts_models/en/jenny/jenny',\n",
       " 'tts_models/es/mai/tacotron2-DDC',\n",
       " 'tts_models/es/css10/vits',\n",
       " 'tts_models/fr/mai/tacotron2-DDC',\n",
       " 'tts_models/fr/css10/vits',\n",
       " 'tts_models/uk/mai/glow-tts',\n",
       " 'tts_models/uk/mai/vits',\n",
       " 'tts_models/zh-CN/baker/tacotron2-DDC-GST',\n",
       " 'tts_models/nl/mai/tacotron2-DDC',\n",
       " 'tts_models/nl/css10/vits',\n",
       " 'tts_models/de/thorsten/tacotron2-DCA',\n",
       " 'tts_models/de/thorsten/vits',\n",
       " 'tts_models/de/thorsten/tacotron2-DDC',\n",
       " 'tts_models/de/css10/vits-neon',\n",
       " 'tts_models/ja/kokoro/tacotron2-DDC',\n",
       " 'tts_models/tr/common-voice/glow-tts',\n",
       " 'tts_models/it/mai_female/glow-tts',\n",
       " 'tts_models/it/mai_female/vits',\n",
       " 'tts_models/it/mai_male/glow-tts',\n",
       " 'tts_models/it/mai_male/vits',\n",
       " 'tts_models/ewe/openbible/vits',\n",
       " 'tts_models/hau/openbible/vits',\n",
       " 'tts_models/lin/openbible/vits',\n",
       " 'tts_models/tw_akuapem/openbible/vits',\n",
       " 'tts_models/tw_asante/openbible/vits',\n",
       " 'tts_models/yor/openbible/vits',\n",
       " 'tts_models/hu/css10/vits',\n",
       " 'tts_models/el/cv/vits',\n",
       " 'tts_models/fi/css10/vits',\n",
       " 'tts_models/hr/cv/vits',\n",
       " 'tts_models/lt/cv/vits',\n",
       " 'tts_models/lv/cv/vits',\n",
       " 'tts_models/mt/cv/vits',\n",
       " 'tts_models/pl/mai_female/vits',\n",
       " 'tts_models/pt/cv/vits',\n",
       " 'tts_models/ro/cv/vits',\n",
       " 'tts_models/sk/cv/vits',\n",
       " 'tts_models/sl/cv/vits',\n",
       " 'tts_models/sv/cv/vits',\n",
       " 'tts_models/ca/custom/vits',\n",
       " 'tts_models/fa/custom/glow-tts',\n",
       " 'tts_models/bn/custom/vits-male',\n",
       " 'tts_models/bn/custom/vits-female']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List available üê∏TTS models and choose the first one\n",
    "TTS.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/en/ljspeech/speedy-speech is already downloaded.\n",
      " > Model's license - apache 2.0\n",
      " > Check https://choosealicense.com/licenses/apache-2.0/ for more info.\n",
      " > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n",
      " > Model's license - apache 2.0\n",
      " > Check https://choosealicense.com/licenses/apache-2.0/ for more info.\n",
      " > Using model: speedy_speech\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Vocoder Model: hifigan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: hifigan_generator\n",
      " > Discriminator Model: hifigan_discriminator\n",
      "Removing weight norm...\n"
     ]
    }
   ],
   "source": [
    "# Init TTS\n",
    "model_name = 'tts_models/en/ljspeech/speedy-speech'\n",
    "tts = TTS(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['This is a test!', 'This is also a test!!']\n",
      " > Processing time: 0.13470673561096191\n",
      " > Real-time factor: 0.03635775950134291\n"
     ]
    }
   ],
   "source": [
    "# Run TTS\n",
    "\n",
    "# ‚ùó Since this model is multi-speaker and multi-lingual, we must set the target speaker and the language\n",
    "# Text to speech with a numpy output\n",
    "wav = tts.tts(\"This is a test! This is also a test!!\")\n",
    "# Text to speech to a file\n",
    "# tts.tts_to_file(text=\"Hello world! This is text\", file_path=\"output.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0008597959"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchaudio.save(\"output.wav\", torch.tensor(wav).unsqueeze(0), 22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Downloading model to /home/gmongaras/.local/share/tts/tts_models--de--thorsten--tacotron2-DDC\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Running a single speaker model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39m# Init TTS with the target model name\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m tts \u001b[39m=\u001b[39m TTS(model_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtts_models/de/thorsten/tacotron2-DDC\u001b[39;49m\u001b[39m\"\u001b[39;49m, progress_bar\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, gpu\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m      5\u001b[0m \u001b[39m# Run TTS\u001b[39;00m\n\u001b[1;32m      6\u001b[0m tts\u001b[39m.\u001b[39mtts_to_file(text\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIch bin eine Testnachricht.\u001b[39m\u001b[39m\"\u001b[39m, file_path\u001b[39m=\u001b[39mOUTPUT_PATH)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/TTS/api.py:289\u001b[0m, in \u001b[0;36mTTS.__init__\u001b[0;34m(self, model_name, model_path, config_path, vocoder_path, vocoder_config_path, progress_bar, gpu)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39mif\u001b[39;00m model_name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtts_models\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m model_name \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcoqui_studio\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m model_name:\n\u001b[0;32m--> 289\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_tts_model_by_name(model_name, gpu)\n\u001b[1;32m    290\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvoice_conversion_models\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m model_name:\n\u001b[1;32m    291\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_vc_model_by_name(model_name, gpu)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/TTS/api.py:385\u001b[0m, in \u001b[0;36mTTS.load_tts_model_by_name\u001b[0;34m(self, model_name, gpu)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcsapi \u001b[39m=\u001b[39m CS_API()\n\u001b[1;32m    384\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 385\u001b[0m     model_path, config_path, vocoder_path, vocoder_config_path, model_dir \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload_model_by_name(\n\u001b[1;32m    386\u001b[0m         model_name\n\u001b[1;32m    387\u001b[0m     )\n\u001b[1;32m    389\u001b[0m     \u001b[39m# init synthesizer\u001b[39;00m\n\u001b[1;32m    390\u001b[0m     \u001b[39m# None values are fetch from the model\u001b[39;00m\n\u001b[1;32m    391\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msynthesizer \u001b[39m=\u001b[39m Synthesizer(\n\u001b[1;32m    392\u001b[0m         tts_checkpoint\u001b[39m=\u001b[39mmodel_path,\n\u001b[1;32m    393\u001b[0m         tts_config_path\u001b[39m=\u001b[39mconfig_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    401\u001b[0m         use_cuda\u001b[39m=\u001b[39mgpu,\n\u001b[1;32m    402\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/TTS/api.py:348\u001b[0m, in \u001b[0;36mTTS.download_model_by_name\u001b[0;34m(self, model_name)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdownload_model_by_name\u001b[39m(\u001b[39mself\u001b[39m, model_name: \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 348\u001b[0m     model_path, config_path, model_item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmanager\u001b[39m.\u001b[39;49mdownload_model(model_name)\n\u001b[1;32m    349\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mfairseq\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m model_name \u001b[39mor\u001b[39;00m (model_item \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(model_item[\u001b[39m\"\u001b[39m\u001b[39mmodel_url\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39mlist\u001b[39m)):\n\u001b[1;32m    350\u001b[0m         \u001b[39m# return model directory if there are multiple files\u001b[39;00m\n\u001b[1;32m    351\u001b[0m         \u001b[39m# we assume that the model knows how to load itself\u001b[39;00m\n\u001b[1;32m    352\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, model_path\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/TTS/utils/manage.py:323\u001b[0m, in \u001b[0;36mModelManager.download_model\u001b[0;34m(self, model_name)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownload_fairseq_model(model_name, output_path)\n\u001b[1;32m    322\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mgithub_rls_url\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m model_item:\n\u001b[0;32m--> 323\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_github_model(model_item, output_path)\n\u001b[1;32m    324\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mhf_url\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m model_item:\n\u001b[1;32m    325\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download_hf_model(model_item, output_path)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/TTS/utils/manage.py:253\u001b[0m, in \u001b[0;36mModelManager._download_github_model\u001b[0;34m(self, model_item, output_path)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download_model_files(model_item[\u001b[39m\"\u001b[39m\u001b[39mgithub_rls_url\u001b[39m\u001b[39m\"\u001b[39m], output_path, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogress_bar)\n\u001b[1;32m    252\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_zip_file(model_item[\u001b[39m\"\u001b[39;49m\u001b[39mgithub_rls_url\u001b[39;49m\u001b[39m\"\u001b[39;49m], output_path, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprogress_bar)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/TTS/utils/manage.py:455\u001b[0m, in \u001b[0;36mModelManager._download_zip_file\u001b[0;34m(file_url, output_folder, progress_bar)\u001b[0m\n\u001b[1;32m    453\u001b[0m temp_zip_name \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_folder, file_url\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    454\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(temp_zip_name, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m--> 455\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m r\u001b[39m.\u001b[39miter_content(block_size):\n\u001b[1;32m    456\u001b[0m         \u001b[39mif\u001b[39;00m progress_bar:\n\u001b[1;32m    457\u001b[0m             progress_bar\u001b[39m.\u001b[39mupdate(\u001b[39mlen\u001b[39m(data))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/urllib3/response.py:628\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    627\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_fp_closed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp):\n\u001b[0;32m--> 628\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(amt\u001b[39m=\u001b[39;49mamt, decode_content\u001b[39m=\u001b[39;49mdecode_content)\n\u001b[1;32m    630\u001b[0m         \u001b[39mif\u001b[39;00m data:\n\u001b[1;32m    631\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/urllib3/response.py:567\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    564\u001b[0m fp_closed \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp, \u001b[39m\"\u001b[39m\u001b[39mclosed\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    566\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 567\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp_read(amt) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fp_closed \u001b[39melse\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    569\u001b[0m         flush_decoder \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/urllib3/response.py:533\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[39mreturn\u001b[39;00m buffer\u001b[39m.\u001b[39mgetvalue()\n\u001b[1;32m    531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     \u001b[39m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 533\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mread(amt) \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mread()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/http/client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m amt \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength:\n\u001b[1;32m    464\u001b[0m     \u001b[39m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     amt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength\n\u001b[0;32m--> 466\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mread(amt)\n\u001b[1;32m    467\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m s \u001b[39mand\u001b[39;00m amt:\n\u001b[1;32m    468\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Running a single speaker model\n",
    "\n",
    "# Init TTS with the target model name\n",
    "tts = TTS(model_name=\"tts_models/de/thorsten/tacotron2-DDC\", progress_bar=False, gpu=False)\n",
    "# Run TTS\n",
    "tts.tts_to_file(text=\"Ich bin eine Testnachricht.\", file_path=OUTPUT_PATH)\n",
    "\n",
    "# Example voice cloning with YourTTS in English, French and Portuguese\n",
    "\n",
    "tts = TTS(model_name=\"tts_models/multilingual/multi-dataset/your_tts\", progress_bar=False, gpu=True)\n",
    "tts.tts_to_file(\"This is voice cloning.\", speaker_wav=\"my/cloning/audio.wav\", language=\"en\", file_path=\"output.wav\")\n",
    "tts.tts_to_file(\"C'est le clonage de la voix.\", speaker_wav=\"my/cloning/audio.wav\", language=\"fr-fr\", file_path=\"output.wav\")\n",
    "tts.tts_to_file(\"Isso √© clonagem de voz.\", speaker_wav=\"my/cloning/audio.wav\", language=\"pt-br\", file_path=\"output.wav\")\n",
    "\n",
    "\n",
    "# Example voice conversion converting speaker of the `source_wav` to the speaker of the `target_wav`\n",
    "\n",
    "tts = TTS(model_name=\"voice_conversion_models/multilingual/vctk/freevc24\", progress_bar=False, gpu=True)\n",
    "tts.voice_conversion_to_file(source_wav=\"my/source.wav\", target_wav=\"my/target.wav\", file_path=\"output.wav\")\n",
    "\n",
    "# Example voice cloning by a single speaker TTS model combining with the voice conversion model. This way, you can\n",
    "# clone voices by using any model in üê∏TTS.\n",
    "\n",
    "tts = TTS(\"tts_models/de/thorsten/tacotron2-DDC\")\n",
    "tts.tts_with_vc_to_file(\n",
    "    \"Wie sage ich auf Italienisch, dass ich dich liebe?\",\n",
    "    speaker_wav=\"target/speaker.wav\",\n",
    "    file_path=\"output.wav\"\n",
    ")\n",
    "\n",
    "# Example text to speech using [üê∏Coqui Studio](https://coqui.ai) models.\n",
    "\n",
    "# You can use all of your available speakers in the studio.\n",
    "# [üê∏Coqui Studio](https://coqui.ai) API token is required. You can get it from the [account page](https://coqui.ai/account).\n",
    "# You should set the `COQUI_STUDIO_TOKEN` environment variable to use the API token.\n",
    "\n",
    "# If you have a valid API token set you will see the studio speakers as separate models in the list.\n",
    "# The name format is coqui_studio/en/<studio_speaker_name>/coqui_studio\n",
    "models = TTS().list_models()\n",
    "# Init TTS with the target studio speaker\n",
    "tts = TTS(model_name=\"coqui_studio/en/Torcull Diarmuid/coqui_studio\", progress_bar=False, gpu=False)\n",
    "# Run TTS\n",
    "tts.tts_to_file(text=\"This is a test.\", file_path=OUTPUT_PATH)\n",
    "# Run TTS with emotion and speed control\n",
    "tts.tts_to_file(text=\"This is a test.\", file_path=OUTPUT_PATH, emotion=\"Happy\", speed=1.5)\n",
    "\n",
    "\n",
    "#Example text to speech using **Fairseq models in ~1100 languages** ü§Ø.\n",
    "\n",
    "#For these models use the following name format: `tts_models/<lang-iso_code>/fairseq/vits`.\n",
    "#You can find the list of language ISO codes [here](https://dl.fbaipublicfiles.com/mms/tts/all-tts-languages.html) and learn about the Fairseq models [here](https://github.com/facebookresearch/fairseq/tree/main/examples/mms).\n",
    "\n",
    "# TTS with on the fly voice conversion\n",
    "api = TTS(\"tts_models/deu/fairseq/vits\")\n",
    "api.tts_with_vc_to_file(\n",
    "    \"Wie sage ich auf Italienisch, dass ich dich liebe?\",\n",
    "    speaker_wav=\"target/speaker.wav\",\n",
    "    file_path=\"output.wav\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
